# -*- coding: utf-8 -*-
from playwright.sync_api import sync_playwright, TimeoutError
import time

# å­˜æ”¾æŠ“å–åˆ°çš„ URL
all_urls = []

# def wait_for_slider_and_manual(page):
#     """
#     æ£€æµ‹æ»‘å—éªŒè¯ç ï¼Œå¦‚æœå‡ºç°å°±ç­‰å¾…äººå·¥å¤„ç†
#     """
#     try:
#         page.wait_for_selector(
#             "iframe[src*='geetest'], .geetest_slider_button",
#             timeout=5000
#         )
#         print("\nâš ï¸ æ£€æµ‹åˆ°æ»‘å—éªŒè¯ç ")
#         print("ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨ä¸­ã€æ‰‹åŠ¨æ‹–åŠ¨æ»‘å—ã€‘")
#         input("âœ”ï¸ å®ŒæˆåæŒ‰ã€å›è½¦ã€‘ç»§ç»­ç¨‹åº...\n")
#         time.sleep(2)  # æ»‘å—å®Œæˆåçš„ç­‰å¾…
#     except TimeoutError:
#         # æ²¡æœ‰æ»‘å—ï¼Œæ­£å¸¸ç»§ç»­
#         pass

with sync_playwright() as p:
    # 1. å¯åŠ¨æµè§ˆå™¨
    browser = p.chromium.launch(headless=False)
    context = browser.new_context()
    page = context.new_page()

    # 2. æ‰“å¼€åŒ—å¤§æ³•å®é¦–é¡µ
    page.goto("https://www.pkulaw.com/")
    page.wait_for_load_state("networkidle")

    # 3. ç‚¹å‡»â€œå¸æ³•è§£é‡Šâ•â€ â†’ â€œå¸æ³•è§£é‡Šâ€
    page.wait_for_selector("#EffectivenessDicport_18_switch", timeout=60000)
    page.locator("#EffectivenessDicport_18_switch").click()
    time.sleep(1)

    page.wait_for_selector("#EffectivenessDicport_19_span", timeout=60000)
    page.locator("#EffectivenessDicport_19_span").click()
    time.sleep(1)

    # 4. ç‚¹å‡»â€œç°è¡Œæœ‰æ•ˆâ€
    page.wait_for_selector("#TimelinessDicport_1_span", timeout=60000)
    page.locator("#TimelinessDicport_1_span").click()
    time.sleep(1)

    # æ£€æµ‹æ»‘å—
    # wait_for_slider_and_manual(page)

    # 5. hover 20 æ¡/é¡µ â†’ ä¸‹æ‹‰ â†’ ç‚¹å‡» 100 æ¡/é¡µ
    page.wait_for_selector(".articleSelect > div:first-child", timeout=60000)
    page.locator(".articleSelect > div:first-child").hover()
    time.sleep(1)

    page.wait_for_selector("dd[filter_value='100']:visible", timeout=60000)
    page.locator("dd[filter_value='100']:visible").click()
    time.sleep(2)

    # æ£€æµ‹æ»‘å—
    # wait_for_slider_and_manual(page)

    # 6. å¾ªç¯æŠ“å–ï¼Œæ¯é¡µæ‰‹åŠ¨ç¿»é¡µï¼Œæœ€å¤š8é¡µ
    page_index = 1
    while page_index <= 7:
        print(f"\nğŸ“„ æ­£åœ¨æŠ“å–ç¬¬ {page_index} é¡µ")

        # ç­‰å¾…æ–‡ç« åˆ—è¡¨åŠ è½½
        page.wait_for_selector("a[flink='true']", timeout=60000)
        links = page.locator("a[flink='true']")
        count = links.count()
        for i in range(count):
            title = links.nth(i).inner_text().strip()
            href = links.nth(i).get_attribute("href")
            if not href:
                continue
            # åªä¿ç•™æ³•è§„æ€»é¡µï¼Œä¸æŠ“ Readchl
            if "/chl/" in href and "listView" in href:
                # è·³è¿‡åŒ…å«â€œå†³å®šâ€æˆ–â€œå†³è®®â€çš„æ³•è§„
                if "å†³å®š" in title or "å†³è®®" in title:
                    continue
                full_url = page.url.split("?")[0].rstrip("/") + href
                all_urls.append((title, full_url))
                print(f"{len(all_urls)}. {title} {full_url}")

        print("\nâœ… å½“å‰é¡µæŠ“å–å®Œæˆ")
        if page_index < 7:
            input("ğŸ‘‰ è¯·æ‰‹åŠ¨ç‚¹å‡»ä¸‹ä¸€é¡µåæŒ‰ã€å›è½¦ã€‘ç»§ç»­æŠ“å–ä¸‹ä¸€é¡µ...\n")
            # wait_for_slider_and_manual(page)
        page_index += 1

    # 7. è¾“å‡ºæ€»æ•°
    print(f"\nå…±æŠ“å– {len(all_urls)} æ¡æ³•è§„ URL")

    # 8. å…³é—­æµè§ˆå™¨
    browser.close()

# 9. ä¿å­˜åˆ°æ–‡ä»¶ï¼Œå¸¦åºå·
with open("pkulaw_judicialExplanation_urls.txt", "w", encoding="utf-8") as f:
    for idx, (title, url) in enumerate(all_urls, 1):
        f.write(f"{idx}. {title}\t{url}\n")

print("å®Œæˆï¼Œå·²ä¿å­˜ pkulaw_judicialExplanation_urls.txt")
